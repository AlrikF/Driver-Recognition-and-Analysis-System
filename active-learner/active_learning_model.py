# -*- coding: utf-8 -*-
"""al_faces_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MHH43EBaufTpJfthX9zltRcpr-_arQ6i
"""

!pip install face_recognition

!pip install opencv-python

"""
Created on Wed Nov 25 18:24:21 2020

@author: ManavChordia
"""

import face_recognition
import os
import pickle
from matplotlib import pyplot as plt
from PIL import Image
import cv2

from google.colab import drive
drive.mount('/content/drive')

folders = (os.listdir("/content/drive/My Drive/driver_classified"))
print(folders)

classes = {}

for i in folders:
    cnt = 0
    for j in ((os.listdir("/content/drive/My Drive/driver_classified/" + i))):
        if cnt == 0:
            classes[i] = []
            image = face_recognition.load_image_file("/content/drive/My Drive/driver_classified/" + i + "/" + j) #load image
            location = face_recognition.face_locations(image,model="cnn") 
            classes[i].append(location)
            cnt = cnt + 1
            print(cnt)
            
        else:
            image = face_recognition.load_image_file("/content/drive/My Drive/driver_classified/" + i + "/" + j) #load image
            location = face_recognition.face_locations(image,model="cnn") 
            classes[i].append(location)
            print(j)

print(classes)

import numpy as np
Y = []
temp = 0
for i in classes:
  print(len(classes[i]))
  for j in range(len(classes[i])):
    Y.append(temp)
  temp = temp + 1

Y = np.array(Y)
print(Y)

!pip install keras-facenet

from keras_facenet import FaceNet
embedder = FaceNet()
detections = []

# Gets a detection dict for each face
# in an image. Each one has the bounding box and
# face landmarks (from mtcnn.MTCNN) along with
# the embedding from FaceNet.
tot_cnt = 0
Y_new = []
count_list = []
Images = []
for i in folders:
  count_1 = 0
  for j in ((os.listdir("/content/drive/My Drive/driver_classified/" + i))):
    detection = embedder.extract("/content/drive/My Drive/driver_classified/" + i + "/" + j, threshold=0.95)
    if len(detection) != 0:# and count_1 < 20:
      detections.append(detection[0]['embedding'])
      Y_new.append(Y[tot_cnt])
      Images.append(cv2.imread("/content/drive/My Drive/driver_classified/" + i + "/" + j))
      tot_cnt = tot_cnt + 1
      count_1 = count_1 + 1
    else:
      tot_cnt = tot_cnt + 1
  count_list.append(count_1)

print(Images[0].shape)

Y = np.array(Y_new)
Images = np.array(Images)
print(Y.shape)
X = np.array(detections)
print(X.shape)
print(count_list)
print(Y[0:5].shape)

#count_list.insert(0,0)
#count_list.pop()
#count_list.insert(0,0)
cnt_list = [0]
for i in range(0, len(count_list)):
  temp = 0
  for j in range(0, i+1):
    temp = temp + count_list[j] 
  cnt_list.append(temp-1)
print(cnt_list)

def train_test_set(X, Y, n, cnt_list):
  y_train = []
  x_train = []
  x_test = []
  y_test = []
  Images_train = []
  Images_test = []
  temp = 0
  #count_list.pop()
  for i in range(len(cnt_list)-1):
    if i != len(cnt_list) - 2:
      x_train.append(X[cnt_list[temp] + 1:cnt_list[temp] + n+1])
      Images_train.append(Images[cnt_list[temp]+1:cnt_list[temp] + n+1])
      x_test.append(X[cnt_list[temp] + n: cnt_list[temp+1]])
      Images_test.append(Images[cnt_list[temp] + n: cnt_list[temp+1]])
      y_train.append( Y[cnt_list[temp]+1:cnt_list[temp] + n+1])
      y_test.append(Y[cnt_list[temp] + n: cnt_list[temp+1]].tolist())
      temp = temp + 1
    else:
      x_test.append(X[cnt_list[temp] :])
      y_test.append(Y[cnt_list[temp] :]) 
      Images_test.append(Images[cnt_list[temp] :])    #print(cnt_list[temp] + n)

  return x_train, y_train, x_test, y_test, Images_train, Images_test

X_train, Y_train, X_test, Y_test, Images_train, Images_test = train_test_set(X, Y, 3, cnt_list)

import itertools
X_train = np.reshape(X_train, (-1, 512))
Y_train = np.reshape(Y_train, (-1,))
Y_test = list(itertools.chain.from_iterable(Y_test))
Y_test = np.array(Y_test)
X_test = np.concatenate((X_test[0], X_test[1], X_test[2], X_test[3]))
Images_train = np.concatenate((Images_train[0], Images_train[1], Images_train[2]))
Images_test = np.concatenate((Images_test[0], Images_test[1], Images_test[2], Images_test[3]))

print(Y_test.shape)#, Y_train.shape, X_test.shape, Y_test.shape )

Y_train_ori = Y_train
print(Y_train_ori.shape)

def shuffle_in_unison(a, b, c):
    assert len(a) == len(b)
    shuffled_a = np.empty(a.shape, dtype=a.dtype)
    shuffled_b = np.empty(b.shape, dtype=b.dtype)
    shuffled_c = np.empty(c.shape, dtype=c.dtype)
    permutation = np.random.permutation(len(a))
    for old_index, new_index in enumerate(permutation):
        shuffled_a[new_index] = a[old_index]
        shuffled_b[new_index] = b[old_index]
        shuffled_c[new_index] = c[old_index]
    return shuffled_a, shuffled_b, shuffled_c

X_train, Y_train, Images_train = shuffle_in_unison(X_train, Y_train, Images_train)
X_test, Y_test, Images_test = shuffle_in_unison(X_test, Y_test, Images_test)

X_f_test = X_test[-30:]
Y_f_test = Y_test[-30:]
X_test = X_test[0:-30]
Y_test = Y_test[0:-30]


print(X_f_test.shape)

!pip install -U scikit-learn

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder

#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=ts)
Y_train = Y_train.reshape(-1,1)
Y_test = Y_test.reshape(-1,1)
#Y_f_test = Y_f_test.reshape(-1,1)



enc = OneHotEncoder(handle_unknown='ignore')
print(Y_train_ori.shape, Y_train.shape)
Y_train = enc.fit_transform(Y_train).toarray()
Y_test = enc.fit_transform(Y_test).toarray()
#Y_f_test = enc.fit_transform(Y_f_test).toarray()

class_count = 3


from keras.layers import Input, Dense, Conv2D, MaxPool2D, UpSampling2D, Dropout, Flatten
from keras.models import Model
from keras.models import Sequential
from keras import backend as K
import keras
def modelFactory(class_count, X_train):
  n_cols = X_train.shape[1]
  model = Sequential([
    keras.layers.Dense(256, activation='relu', input_shape=(n_cols,)),
    keras.layers.Dropout(0.2),
    keras.layers.Dense(class_count, activation= 'softmax', input_shape=(n_cols,))
  ])
  #model.add(Dense(128, activation = 'relu'))
  #model.add(Dropout(0.5))
  #model.add(Dense(64, activation = 'relu'))
  #model.add(Dropout(0.5))
  #opt = keras.optimizers.Adam(learning_rate = 0.0005)
  
  model.compile(optimizer='adam', loss="categorical_crossentropy", metrics=['accuracy'])
  model.summary()

  return model

#history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_test, Y_test), verbose=1)
#print(history.history['val_accuracy'][-1])
#return history.history['val_accuracy'][-1]

import math
def entropy(thing):
    ent = 0
    
    for i in thing:
        if i == 0:
            i = i + 0.00001
        ent = ent + i * math.log(i, 2)
        
    return -ent

def do_one_hot_encoding(arr):
  print("in func")
  arr = enc.fit_transform(arr.reshape(-1,1)).toarray()
  print("returning")
  return arr

from google.colab.patches import cv2_imshow
from IPython.display import Image
from IPython.display import Image, display


def activeLearning(ent_thresh, tc, c, X_train, Y_train, X_test, Y_test, Images_train, Images_test, Y_train_ori, model):
        
    global class_count
    num_iter = 0
    tot_cntr = 0
    #model = model(class_count)
    while 1: 
        print("in while")
        
        if num_iter == 0:
            #model = model(class_count, X_train)
            model.summary()
            model.fit(X_train, Y_train, epochs=30, verbose=1)
            Y_pred = model.predict(X_test)
            num_iter = num_iter + 1
            
            all_entropies = []
            for i in Y_pred:
                all_entropies.append(entropy(i))
            print(all_entropies)
            all_entropies = np.array(all_entropies)
                
        else:
            print("in else 1")
            
            counter = 0
            not_to_be_removed = []
            not_to_be_removed_y = []
            not_to_be_removed_images = []
            to_be_removed = 0
            for i in range(0, len(all_entropies)):
                if i in all_entropies.argsort()[-5:][::-1] and counter < c and tot_cntr < tc:
                    #print("in if 2")
                    counter = counter + 1
                    tot_cntr = tot_cntr + 1
                    print(Y_test[i])

                    #cv2_imshow(Images_test[i])

                    #cv2.waitKey(1)
                    #cv2.destroyAllWindows()

                    display(0)

                    plt.imshow(Images_test[i])
                    plt.show()
                    print("here 1")
                    y_in = int(input("enter correct class for x_test[" + str(i) + "]"))

                    if y_in >= class_count:
                      print("in this if")
                      class_count = class_count + 1
                      print(class_count)

                    Y_train_ori = np.append(Y_train_ori, y_in)
                    X_train = np.concatenate((X_train, X_test[i].reshape(1, -1)))
                    
                    Y_train = do_one_hot_encoding(Y_train_ori)
                    print(Y_train)
                    print(Y_train_ori)

                    

                    print("here 2")
                    #X_train = np.concatenate((X_train, X_test[i].reshape(1, -1)))
                    Images_train = np.concatenate((Images_train, Images_test[i].reshape(1, Images_test[i].shape[0], -1, 3)))
                    to_be_removed += 1
                            
                else:
                    #print("in else 2")
                    not_to_be_removed.append(X_test[i])
                    not_to_be_removed_y.append(Y_test[i])
                    not_to_be_removed_images.append(Images_test[i])
                    
            X_test = np.array(not_to_be_removed) 
            Y_test = np.array(not_to_be_removed_y)
            Images_test = np.array(not_to_be_removed_images)
                
            if to_be_removed == 0:
                    #print("breaking.......")
                    break
                                    
            print("here 3")
            
            print(X_train.shape)
            model = modelFactory(class_count, X_train)
            model.fit(X_train, Y_train , epochs=30, verbose=1)
            Y_pred = model.predict(X_test)
            num_iter = num_iter + 1
            print("num _t iter = " + str(num_iter))
            
            print("here 4")

            all_entropies = []
            for i in Y_pred:
                all_entropies.append(entropy(i))
            all_entropies = np.array(all_entropies)
            
                
    
                
    return Y_pred, model

# Commented out IPython magic to ensure Python compatibility.
# %debug
model = modelFactory(class_count, X_train)
Y_pred, model_1 = activeLearning(0.00005, 30, 5, X_train, Y_train, X_test, Y_test, Images_train, Images_test, Y_train_ori, model)

print(Y_train_ori, class_count)

print(model_1.summary())
Y_f_pred = model_1.predict(X_f_test)
print(Y_f_pred)

Y_f_pred = [np.argmax(Y_f_pred[i]) for i in range(0,30)]
print(Y_f_pred)
print(Y_f_test)
from sklearn.metrics import f1_score
f1_scores = []
for i in range(0, 4):
    f1_scores.append(f1_score(Y_f_test, Y_f_pred, labels = [i], average = 'macro'))

f1_score = f1_score(Y_f_test, Y_f_pred, average = 'macro')

print(f1_scores)
print(f1_score)

"""
import matplotlib.pyplot as plt

x = [1,2,3,4,5,6,7]
y = [0.54733742862212933, 0.6784919763399879, 0.7830995782807702, 1, 1, 1, 1]

plt.plot(x, y, label = 'AL')
plt.xlabel('subjects per class')
plt.ylabel('f1_score')
plt.show()
"""